{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import scala.io.Source\n",
       "import java.io.{File, PrintWriter}\n",
       "import org.apache.spark.sql.{SparkSession, DataFrame, Row}\n",
       "import org.apache.spark.sql.types.{StructType, StructField, StringType}\n",
       "import org.apache.spark.sql.functions.{col, split, regexp_replace, when}\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.io.Source\n",
    "import java.io.{File, PrintWriter}\n",
    "import org.apache.spark.sql.{SparkSession, DataFrame, Row}\n",
    "import org.apache.spark.sql.types.{StructType, StructField, StringType}\n",
    "import org.apache.spark.sql.functions.{col, split, regexp_replace, when}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2e38f42\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder\n",
    "    .appName(\"medi_test\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rootPath: String = /Users/b06/Desktop/yeardream/medi-05\n",
       "jsonRootPath: String = /Users/b06/Desktop/yeardream/medi-05/data/naverplace_meta\n",
       "saveRootPath: String = /Users/b06/Desktop/yeardream/medi-05/spark-scala-project/output/scala\n",
       "textRootPath: String = /Users/b06/Desktop/yeardream/medi-05/spark-scala-project/test.txt\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rootPath = \"/Users/b06/Desktop/yeardream/medi-05\"\n",
    "val jsonRootPath = s\"$rootPath/data/naverplace_meta\"\n",
    "val saveRootPath = s\"$rootPath/spark-scala-project/output/scala\"\n",
    "val textRootPath = s\"$rootPath/spark-scala-project/test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readText: (filePath: String)String\n",
       "readJson: (n: String, jsonRootPath: String)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readText(filePath: String): String = {\n",
    "    val file = Source.fromFile(filePath)\n",
    "    val lines = file.getLines.toList\n",
    "    file.close()\n",
    "    val n = if (lines.nonEmpty) lines.head.trim else \"\"\n",
    "    if (lines.nonEmpty) {\n",
    "        val remainingLines = lines.tail\n",
    "        val writer = new PrintWriter(new File(filePath))\n",
    "        remainingLines.foreach(writer.println)\n",
    "        writer.close()\n",
    "    }\n",
    "    n\n",
    "}\n",
    "\n",
    "def readJson(n: String, jsonRootPath: String): DataFrame = {\n",
    "    val jsonPath = s\"$jsonRootPath/naverplace_meta_$n.json\"\n",
    "    spark.read.option(\"multiline\", \"true\").json(jsonPath)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "n: String = 1\n",
       "data: org.apache.spark.sql.DataFrame = [BaseNaverBlog:betbetter: struct<__typename: string, categoryNo: string ... 1 more field>, BaseNaverBlog:bondiolsc: struct<__typename: string, categoryNo: string ... 1 more field> ... 469 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val n = readText(textRootPath)\n",
    "println(n)\n",
    "val data = readJson(n, jsonRootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columns: Array[String] = Array(BaseNaverBlog:betbetter, BaseNaverBlog:bondiolsc, BaseNaverBlog:dainhani, BaseNaverBlog:kundaeclinic, BaseNaverBlog:memeetsworld, BaseNaverBlog:orot-hani, BaseNaverBlog:zzz0501, BusStation:104073, BusStation:104091, BusStation:104094, BusStation:104132, BusStation:104140, BusStation:104154, BusStation:104158, BusStation:104172, BusStation:104181, BusStation:104212, BusStation:104222, BusStation:104231, BusStation:104321, BusStation:104386, BusStation:104395, BusStation:104428, BusStation:104440, BusStation:104459, BusStation:104500, BusStation:104507, BusStation:104517, BusStation:104532, BusStation:104544, BusStation:104554, BusStation:104573, BusStation:104576, BusStation:104578, BusStation:104580, BusStation:104582, BusStation:104594, BusStation:104598,...\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columns = data.columns\n",
    "val hospitalBases = columns.filter(_.contains(\"HospitalBase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dfSchema: org.apache.spark.sql.types.StructType = StructType(StructField(id,StringType,true),StructField(name,StringType,true),StructField(review_keywords,StringType,true),StructField(description,StringType,true),StructField(road,StringType,true),StructField(booking_business_id,StringType,true),StructField(booking_display_name,StringType,true),StructField(category,StringType,true),StructField(category_code,StringType,true),StructField(category_code_list,StringType,true),StructField(category_count,StringType,true),StructField(rcode,StringType,true),StructField(virtual_phone,StringType,true),StructField(phone,StringType,true),StructField(naver_booking_url,StringType,true),StructField(conveniences,StringType,true),StructField(talktalk_url,StringType,true),StructField(road_address,StringTyp...\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dfSchema = StructType(Seq(\n",
    "    StructField(\"id\", StringType, nullable = true),\n",
    "    StructField(\"name\", StringType, nullable = true),\n",
    "    StructField(\"review_keywords\", StringType, nullable = true),\n",
    "    StructField(\"description\", StringType, nullable = true),\n",
    "    StructField(\"road\", StringType, nullable = true),\n",
    "    StructField(\"booking_business_id\", StringType, nullable = true),\n",
    "    StructField(\"booking_display_name\", StringType, nullable = true),\n",
    "    StructField(\"category\", StringType, nullable = true),\n",
    "    StructField(\"category_code\", StringType, nullable = true),\n",
    "    StructField(\"category_code_list\", StringType, nullable = true),\n",
    "    StructField(\"category_count\", StringType, nullable = true),\n",
    "    StructField(\"rcode\", StringType, nullable = true),\n",
    "    StructField(\"virtual_phone\", StringType, nullable = true),\n",
    "    StructField(\"phone\", StringType, nullable = true),\n",
    "    StructField(\"naver_booking_url\", StringType, nullable = true),\n",
    "    StructField(\"conveniences\", StringType, nullable = true),\n",
    "    StructField(\"talktalk_url\", StringType, nullable = true),\n",
    "    StructField(\"road_address\", StringType, nullable = true),\n",
    "    StructField(\"keywords\", StringType, nullable = true),\n",
    "    StructField(\"payment_info\", StringType, nullable = true),\n",
    "    StructField(\"ref\", StringType, nullable = true),\n",
    "    StructField(\"lon\", StringType, nullable = true),\n",
    "    StructField(\"lat\", StringType, nullable = true)\n",
    "))\n",
    "val df = spark.createDataFrame(spark.sparkContext.emptyRDD[Row], dfSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "71: error: constructor cannot be instantiated to expected type;",
     "output_type": "error",
     "traceback": [
      "<console>:71: error: constructor cannot be instantiated to expected type;",
      " found   : Some[A]",
      " required: org.apache.spark.sql.Row",
      "               case Some(row) =>",
      "                    ^",
      "<console>:75: error: pattern type is incompatible with expected type;",
      " found   : None.type",
      " required: org.apache.spark.sql.Row",
      "               case None => None",
      "                    ^",
      ""
     ]
    }
   ],
   "source": [
    "def getValue(data: DataFrame, baseId: String, key: String) = {\n",
    "  val columnKey = s\"HospitalBase:$baseId.$key\"\n",
    "  val column = data.select(columnKey)\n",
    "  val row = column.filter(!col(key).isNull)\n",
    "  val value = row.first\n",
    "  value\n",
    "}\n",
    "\n",
    "def replaceExprAndGetValues(value: Option[String]) = {\n",
    "  value match {\n",
    "    case Some(v) =>\n",
    "      val replacedValue = v.replaceAll(\"\\n|\\r|,|\\\\*\", \"\")\n",
    "      Some(replacedValue)\n",
    "    case None => None\n",
    "  }\n",
    "}\n",
    "\n",
    "def checkNone(value: Option[String]) = {\n",
    "  value match {\n",
    "    case Some(v) => Some(v.charAt(0))\n",
    "    case None => None\n",
    "  }\n",
    "}\n",
    "\n",
    "def getLonLatValues(refValue: Option[String], data: DataFrame) = {\n",
    "  refValue match {\n",
    "    case Some(rv) =>\n",
    "      val panoramaKey = rv.split(\":\")(1)\n",
    "      val panoramaData = data.selectExpr(s\"`Panorama:$panoramaKey` as panorama_data\")\n",
    "      val panoramaValue = panoramaData.filter(!col(\"panorama_data\").isNull).first\n",
    "\n",
    "      panoramaValue match {\n",
    "        case Some(row) =>\n",
    "          val lon = row.getMap[String, Double](0)(\"lon\")\n",
    "          val lat = row.getMap[String, Double](0)(\"lat\")\n",
    "          Some(Map(\"lon\" -> lon, \"lat\" -> lat))\n",
    "        case None => None\n",
    "      }\n",
    "    case None => None\n",
    "  }\n",
    "}\n",
    "\n",
    "def createBooleanColumn(df: DataFrame, targetColumn: String, createColumn: String, value: Option[String] = None) = {\n",
    "  val condition = value match {\n",
    "    case Some(v) => col(targetColumn).isNotNull && col(targetColumn).contains(v)\n",
    "    case None    => col(targetColumn).isNotNull && col(targetColumn) =!= \"\"\n",
    "  }\n",
    "  df.withColumn(createColumn, when(condition, true).otherwise(false))\n",
    "}\n",
    "\n",
    "def expandColumn(df: DataFrame, column: String, maxNum: Int) = {\n",
    "  val createArray = s\"${column}_array\"\n",
    "  var newDf = df.withColumn(createArray, split(col(column), \",\"))\n",
    "  for (i <- 0 until maxNum) {\n",
    "    newDf = newDf.withColumn(s\"${column}_${i + 1}\", col(createArray)(i))\n",
    "  }\n",
    "  newDf\n",
    "}\n",
    "\n",
    "def replaceExprInKeywordColumns(df: DataFrame) = {\n",
    "  var newDf = df\n",
    "  for (i <- 1 to 5) {\n",
    "    val keywordColumn = s\"keywords_$i\"\n",
    "    newDf = newDf.withColumn(\n",
    "      keywordColumn,\n",
    "      when(col(keywordColumn).isNotNull, regexp_replace(col(keywordColumn), \"[\\\\[\\\\]]\", \"\"))\n",
    "    )\n",
    "  }\n",
    "  newDf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "70: error: type mismatch;",
     "output_type": "error",
     "traceback": [
      "<console>:70: error: type mismatch;",
      " found   : String",
      " required: org.apache.spark.sql.Row",
      "               getLonLatValues(rv, data)",
      "                               ^",
      ""
     ]
    }
   ],
   "source": [
    "var hospitalData = Seq[Row]()\n",
    "for (hospitalBase <- hospitalBases) {\n",
    "    val baseId = hospitalBase.split(\":\")(1).trim\n",
    "    val idValue = getValue(data, baseId, \"id\")\n",
    "    val nameValue = getValue(data, baseId, \"name\")\n",
    "    val reviewKeywordsValue = getValue(data, baseId, \"reviewSettings\").map(_.getAs[String](0))\n",
    "    val descriptionValue = getValue(data, baseId, \"description\").map(_.getAs[String](0))\n",
    "    val roadValue = getValue(data, baseId, \"road\").map(_.getAs[String](0))\n",
    "    val bookingBusinessIdValue = getValue(data, baseId, \"bookingBusinessId\").map(_.getAs[String](0))\n",
    "    val bookingDisplayNameValue = getValue(data, baseId, \"bookingDisplayName\").map(_.getAs[String](0))\n",
    "    val categoryValue = getValue(data, baseId, \"category\").map(_.getAs[String](0))\n",
    "    val categoryCodeValue = getValue(data, baseId, \"categoryCode\").map(_.getAs[String](0))\n",
    "    val categoryCodeListValue = getValue(data, baseId, \"categoryCodeList\").map(_.getAs[String](0))\n",
    "    val categoryCountValue = getValue(data, baseId, \"categoryCount\").map(_.getAs[String](0))\n",
    "    val rcodeValue = getValue(data, baseId, \"rcode\").map(_.getAs[String](0))\n",
    "    val virtualPhoneValue = getValue(data, baseId, \"virtualPhone\").map(_.getAs[String](0))\n",
    "    val phoneValue = getValue(data, baseId, \"phone\").map(_.getAs[String](0))\n",
    "    val naverBookingUrlValue = getValue(data, baseId, \"naverBookingUrl\").map(_.getAs[String](0))\n",
    "    val conveniencesValue = getValue(data, baseId, \"conveniences\").map(_.getAs[String](0))\n",
    "    val talktalkUrlValue = getValue(data, baseId, \"talktalkUrl\").map(_.getAs[String](0))\n",
    "    val roadAddressValue = getValue(data, baseId, \"roadAddress\").map(_.getAs[String](0))\n",
    "    val keywordsValue = getValue(data, baseId, \"keywords\").map(_.getAs[String](0))\n",
    "    val paymentInfoValue = getValue(data, baseId, \"paymentInfo\").map(_.getAs[String](0))\n",
    "    val streetPanoramaValue = getValue(data, baseId, \"streetPanorama\")\n",
    "    val refValue = streetPanoramaValue.flatMap(spv => Option(spv.getAs[String](\"__ref\")))\n",
    "    val lonLatValues = refValue.flatMap { rv =>\n",
    "        print(rv)\n",
    "        getLonLatValues(rv, data)\n",
    "    }.getOrElse((null, null))\n",
    "\n",
    "    val roadValueReplaced = roadValue.map(_.replaceAll(\"\\n|\\r|,|\\\\*\", \"\"))\n",
    "    val descriptionValueReplaced = descriptionValue.map(_.replaceAll(\"\\n|\\r|,|\\\\*\", \"\"))\n",
    "    val reviewKeywordsValueReplaced = reviewKeywordsValue.map(_.replaceAll(\"\\\\\\\\\", \"\").replaceAll(\"\\\"\", \"\"))\n",
    "    println(s\"replaced HospitalBase:$baseId's expressions\")\n",
    "\n",
    "    val row = Row(\n",
    "        baseId,\n",
    "        nameValue.getOrElse(null),\n",
    "        reviewKeywordsValueReplaced.getOrElse(null),\n",
    "        descriptionValueReplaced.getOrElse(null),\n",
    "        roadValueReplaced.getOrElse(null),\n",
    "        bookingBusinessIdValue.getOrElse(null),\n",
    "        bookingDisplayNameValue.getOrElse(null),\n",
    "        categoryValue.getOrElse(null),\n",
    "        categoryCodeValue.getOrElse(null),\n",
    "        categoryCodeListValue.getOrElse(null),\n",
    "        categoryCountValue.getOrElse(null),\n",
    "        rcodeValue.getOrElse(null),\n",
    "        virtualPhoneValue.getOrElse(null),\n",
    "        phoneValue.getOrElse(null),\n",
    "        naverBookingUrlValue.getOrElse(null),\n",
    "        conveniencesValue.getOrElse(null),\n",
    "        talktalkUrlValue.getOrElse(null),\n",
    "        roadAddressValue.getOrElse(null),\n",
    "        keywordsValue.getOrElse(null),\n",
    "        paymentInfoValue.getOrElse(null),\n",
    "        refValue.getOrElse(null),\n",
    "        lonLatValues._1,\n",
    "        lonLatValues._2\n",
    "    )\n",
    "    hospitalData = hospitalData :+ row\n",
    "    println(s\"appended HospitalBase:$baseId's rows\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
